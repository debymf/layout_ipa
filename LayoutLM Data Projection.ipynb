{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from loguru import logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA = \"data/rico_sca/rico_sca_test_sample_sample.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(file_location):\n",
    "        parsed_data = dict()\n",
    "        logger.info(\"Preprocessing Rico SCA dataset\")\n",
    "        with open(file_location, \"r\") as f:\n",
    "            input_data = json.load(f)\n",
    "\n",
    "        number_of_screens = len(input_data)\n",
    "        total_screen_elements = 0\n",
    "        total_entries = 0\n",
    "        largest = 0\n",
    "        removed_entry = 0\n",
    "\n",
    "        for _, screen_info in input_data.items():\n",
    "            ui_elements_dict = dict()\n",
    "            index_ui_element = 0\n",
    "\n",
    "            total_screen_elements = (\n",
    "                len(screen_info[\"ui_obj_str_seq\"]) + total_screen_elements\n",
    "            )\n",
    "            for ui_element in screen_info[\"ui_obj_str_seq\"]:\n",
    "\n",
    "                ui_elements_dict[index_ui_element] = {\n",
    "                    \"text\": ui_element,\n",
    "                    \"x0\": screen_info[\"ui_obj_cord_x_seq\"][index_ui_element * 2] * 1000,\n",
    "                    \"x1\": screen_info[\"ui_obj_cord_x_seq\"][(2 * index_ui_element) + 1]\n",
    "                    * 1000,\n",
    "                    \"y0\": screen_info[\"ui_obj_cord_y_seq\"][index_ui_element * 2] * 1000,\n",
    "                    \"y1\": screen_info[\"ui_obj_cord_y_seq\"][(2 * index_ui_element) + 1]\n",
    "                    * 1000,\n",
    "                }\n",
    "                index_ui_element = index_ui_element + 1\n",
    "\n",
    "            index_instruction = 0\n",
    "            for instruction in screen_info[\"instruction_str\"]:\n",
    "                selected_ui_element = screen_info[\"ui_target_id_seq\"][index_instruction]\n",
    "                if screen_info[\"instruction_rule_id\"][index_instruction] == 1 or screen_info[\"instruction_rule_id\"][index_instruction] == 2:\n",
    "                    parsed_data[total_entries] = {\n",
    "                        \"instruction\": instruction,\n",
    "                        \"ui\": ui_elements_dict,\n",
    "                        \"label\": selected_ui_element,\n",
    "                    }\n",
    "\n",
    "                    if len(screen_info[\"ui_obj_str_seq\"]) > largest:\n",
    "                        largest = len(screen_info[\"ui_obj_str_seq\"])\n",
    "\n",
    "                    total_entries = total_entries + 1\n",
    "\n",
    "                index_instruction = index_instruction + 1\n",
    "\n",
    "        logger.info(f\"Largest index of selected UI element:{largest}\")\n",
    "        logger.info(f\"Number of different screens: {number_of_screens}.\")\n",
    "        logger.info(f\"Total Entries: {total_entries}\")\n",
    "        logger.info(f\"Number of removed entries: {removed_entry}\")\n",
    "\n",
    "        return parsed_data, largest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-13 10:04:19.093 | INFO     | __main__:prep_data:3 - Preprocessing Rico SCA dataset\n",
      "2021-01-13 10:04:19.295 | INFO     | __main__:prep_data:50 - Largest index of selected UI element:53\n",
      "2021-01-13 10:04:19.296 | INFO     | __main__:prep_data:51 - Number of different screens: 70.\n",
      "2021-01-13 10:04:19.297 | INFO     | __main__:prep_data:52 - Total Entries: 391\n",
      "2021-01-13 10:04:19.297 | INFO     | __main__:prep_data:53 - Number of removed entries: 0\n"
     ]
    }
   ],
   "source": [
    "dataset, largest = prep_data(TRAIN_DATA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Embeddings for each UI Element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import AutoTokenizer, BertTokenizer, RobertaTokenizer, AutoModel, AutoConfig\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "MODEL_NAME = \"data/models/layoutlm-base-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_ui_to_feature(\n",
    "        example,\n",
    "        max_seq_length,\n",
    "        tokenizer,\n",
    "        cls_token_at_end=False,\n",
    "        cls_token=\"[CLS]\",\n",
    "        cls_token_segment_id=1,\n",
    "        sep_token=\"[SEP]\",\n",
    "        sep_token_extra=False,\n",
    "        pad_on_left=False,\n",
    "        pad_token=0,\n",
    "        cls_token_box=[0, 0, 0, 0],\n",
    "        sep_token_box=[1000, 1000, 1000, 1000],\n",
    "        pad_token_box=[0, 0, 0, 0],\n",
    "        pad_token_segment_id=0,\n",
    "        pad_token_label_id=-1,\n",
    "        sequence_a_segment_id=0,\n",
    "        mask_padding_with_zero=True,\n",
    "    ):\n",
    "        \"\"\" Loads a data file into a list of `InputBatch`s\n",
    "            `cls_token_at_end` define the location of the CLS token:\n",
    "                - False (Default, BERT/XLM pattern): [CLS] + A + [SEP] + B + [SEP]\n",
    "                - True (XLNet/GPT pattern): A + [SEP] + B + [SEP] + [CLS]\n",
    "            `cls_token_segment_id` define the segment id associated to the CLS token (0 for BERT, 2 for XLNet)\n",
    "        \"\"\"\n",
    "\n",
    "        box = [example[\"x0\"], example[\"y0\"], example[\"x1\"], example[\"y1\"]]\n",
    "        tokens = tokenizer.tokenize(example[\"text\"])\n",
    "        token_boxes = [box] * len(tokens)\n",
    "        special_tokens_count = 3 if sep_token_extra else 2\n",
    "        if len(tokens) > max_seq_length - special_tokens_count:\n",
    "            tokens = tokens[: (max_seq_length - special_tokens_count)]\n",
    "            token_boxes = token_boxes[: (max_seq_length - special_tokens_count)]\n",
    "\n",
    "        tokens += [sep_token]\n",
    "        token_boxes += [sep_token_box]\n",
    "        if sep_token_extra:\n",
    "            # roberta uses an extra separator b/w pairs of sentences\n",
    "            tokens += [sep_token]\n",
    "            token_boxes += [sep_token_box]\n",
    "        segment_ids = [sequence_a_segment_id] * len(tokens)\n",
    "\n",
    "        if cls_token_at_end:\n",
    "            tokens += [cls_token]\n",
    "            token_boxes += [cls_token_box]\n",
    "            segment_ids += [cls_token_segment_id]\n",
    "        else:\n",
    "            tokens = [cls_token] + tokens\n",
    "            token_boxes = [cls_token_box] + token_boxes\n",
    "            segment_ids = [cls_token_segment_id] + segment_ids\n",
    "\n",
    "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "        # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "        # tokens are attended to.\n",
    "        input_mask = [1 if mask_padding_with_zero else 0] * len(input_ids)\n",
    "\n",
    "        # Zero-pad up to the sequence length.\n",
    "        padding_length = max_seq_length - len(input_ids)\n",
    "        if pad_on_left:\n",
    "            input_ids = ([pad_token] * padding_length) + input_ids\n",
    "            input_mask = (\n",
    "                [0 if mask_padding_with_zero else 1] * padding_length\n",
    "            ) + input_mask\n",
    "            segment_ids = ([pad_token_segment_id] * padding_length) + segment_ids\n",
    "            token_boxes = ([pad_token_box] * padding_length) + token_boxes\n",
    "        else:\n",
    "            input_ids += [pad_token] * padding_length\n",
    "            input_mask += [0 if mask_padding_with_zero else 1] * padding_length\n",
    "            segment_ids += [pad_token_segment_id] * padding_length\n",
    "            token_boxes += [pad_token_box] * padding_length\n",
    "\n",
    "        assert len(input_ids) == max_seq_length\n",
    "        assert len(input_mask) == max_seq_length\n",
    "        assert len(segment_ids) == max_seq_length\n",
    "        assert len(token_boxes) == max_seq_length\n",
    "\n",
    "        features = {\n",
    "            \"input_ids\": torch.LongTensor(input_ids).view(1,-1),\n",
    "            \"position_ids\": torch.LongTensor(input_mask).view(1,-1),\n",
    "            \"token_type_ids\": torch.LongTensor(segment_ids).view(1,-1),\n",
    "            \"bbox\": torch.LongTensor(token_boxes).view(1,-1,4)\n",
    "\n",
    "        }\n",
    "        \n",
    "\n",
    "        return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at data/models/layoutlm-base-uncased were not used when initializing LayoutLMModel: ['bert.embeddings.word_embeddings.weight', 'bert.embeddings.position_embeddings.weight', 'bert.embeddings.x_position_embeddings.weight', 'bert.embeddings.y_position_embeddings.weight', 'bert.embeddings.h_position_embeddings.weight', 'bert.embeddings.w_position_embeddings.weight', 'bert.embeddings.token_type_embeddings.weight', 'bert.embeddings.LayerNorm.weight', 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.self.query.weight', 'bert.encoder.layer.0.attention.self.query.bias', 'bert.encoder.layer.0.attention.self.key.weight', 'bert.encoder.layer.0.attention.self.key.bias', 'bert.encoder.layer.0.attention.self.value.weight', 'bert.encoder.layer.0.attention.self.value.bias', 'bert.encoder.layer.0.attention.output.dense.weight', 'bert.encoder.layer.0.attention.output.dense.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.bias', 'bert.encoder.layer.0.intermediate.dense.weight', 'bert.encoder.layer.0.intermediate.dense.bias', 'bert.encoder.layer.0.output.dense.weight', 'bert.encoder.layer.0.output.dense.bias', 'bert.encoder.layer.0.output.LayerNorm.weight', 'bert.encoder.layer.0.output.LayerNorm.bias', 'bert.encoder.layer.1.attention.self.query.weight', 'bert.encoder.layer.1.attention.self.query.bias', 'bert.encoder.layer.1.attention.self.key.weight', 'bert.encoder.layer.1.attention.self.key.bias', 'bert.encoder.layer.1.attention.self.value.weight', 'bert.encoder.layer.1.attention.self.value.bias', 'bert.encoder.layer.1.attention.output.dense.weight', 'bert.encoder.layer.1.attention.output.dense.bias', 'bert.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.encoder.layer.1.intermediate.dense.weight', 'bert.encoder.layer.1.intermediate.dense.bias', 'bert.encoder.layer.1.output.dense.weight', 'bert.encoder.layer.1.output.dense.bias', 'bert.encoder.layer.1.output.LayerNorm.weight', 'bert.encoder.layer.1.output.LayerNorm.bias', 'bert.encoder.layer.2.attention.self.query.weight', 'bert.encoder.layer.2.attention.self.query.bias', 'bert.encoder.layer.2.attention.self.key.weight', 'bert.encoder.layer.2.attention.self.key.bias', 'bert.encoder.layer.2.attention.self.value.weight', 'bert.encoder.layer.2.attention.self.value.bias', 'bert.encoder.layer.2.attention.output.dense.weight', 'bert.encoder.layer.2.attention.output.dense.bias', 'bert.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.encoder.layer.2.intermediate.dense.weight', 'bert.encoder.layer.2.intermediate.dense.bias', 'bert.encoder.layer.2.output.dense.weight', 'bert.encoder.layer.2.output.dense.bias', 'bert.encoder.layer.2.output.LayerNorm.weight', 'bert.encoder.layer.2.output.LayerNorm.bias', 'bert.encoder.layer.3.attention.self.query.weight', 'bert.encoder.layer.3.attention.self.query.bias', 'bert.encoder.layer.3.attention.self.key.weight', 'bert.encoder.layer.3.attention.self.key.bias', 'bert.encoder.layer.3.attention.self.value.weight', 'bert.encoder.layer.3.attention.self.value.bias', 'bert.encoder.layer.3.attention.output.dense.weight', 'bert.encoder.layer.3.attention.output.dense.bias', 'bert.encoder.layer.3.attention.output.LayerNorm.weight', 'bert.encoder.layer.3.attention.output.LayerNorm.bias', 'bert.encoder.layer.3.intermediate.dense.weight', 'bert.encoder.layer.3.intermediate.dense.bias', 'bert.encoder.layer.3.output.dense.weight', 'bert.encoder.layer.3.output.dense.bias', 'bert.encoder.layer.3.output.LayerNorm.weight', 'bert.encoder.layer.3.output.LayerNorm.bias', 'bert.encoder.layer.4.attention.self.query.weight', 'bert.encoder.layer.4.attention.self.query.bias', 'bert.encoder.layer.4.attention.self.key.weight', 'bert.encoder.layer.4.attention.self.key.bias', 'bert.encoder.layer.4.attention.self.value.weight', 'bert.encoder.layer.4.attention.self.value.bias', 'bert.encoder.layer.4.attention.output.dense.weight', 'bert.encoder.layer.4.attention.output.dense.bias', 'bert.encoder.layer.4.attention.output.LayerNorm.weight', 'bert.encoder.layer.4.attention.output.LayerNorm.bias', 'bert.encoder.layer.4.intermediate.dense.weight', 'bert.encoder.layer.4.intermediate.dense.bias', 'bert.encoder.layer.4.output.dense.weight', 'bert.encoder.layer.4.output.dense.bias', 'bert.encoder.layer.4.output.LayerNorm.weight', 'bert.encoder.layer.4.output.LayerNorm.bias', 'bert.encoder.layer.5.attention.self.query.weight', 'bert.encoder.layer.5.attention.self.query.bias', 'bert.encoder.layer.5.attention.self.key.weight', 'bert.encoder.layer.5.attention.self.key.bias', 'bert.encoder.layer.5.attention.self.value.weight', 'bert.encoder.layer.5.attention.self.value.bias', 'bert.encoder.layer.5.attention.output.dense.weight', 'bert.encoder.layer.5.attention.output.dense.bias', 'bert.encoder.layer.5.attention.output.LayerNorm.weight', 'bert.encoder.layer.5.attention.output.LayerNorm.bias', 'bert.encoder.layer.5.intermediate.dense.weight', 'bert.encoder.layer.5.intermediate.dense.bias', 'bert.encoder.layer.5.output.dense.weight', 'bert.encoder.layer.5.output.dense.bias', 'bert.encoder.layer.5.output.LayerNorm.weight', 'bert.encoder.layer.5.output.LayerNorm.bias', 'bert.encoder.layer.6.attention.self.query.weight', 'bert.encoder.layer.6.attention.self.query.bias', 'bert.encoder.layer.6.attention.self.key.weight', 'bert.encoder.layer.6.attention.self.key.bias', 'bert.encoder.layer.6.attention.self.value.weight', 'bert.encoder.layer.6.attention.self.value.bias', 'bert.encoder.layer.6.attention.output.dense.weight', 'bert.encoder.layer.6.attention.output.dense.bias', 'bert.encoder.layer.6.attention.output.LayerNorm.weight', 'bert.encoder.layer.6.attention.output.LayerNorm.bias', 'bert.encoder.layer.6.intermediate.dense.weight', 'bert.encoder.layer.6.intermediate.dense.bias', 'bert.encoder.layer.6.output.dense.weight', 'bert.encoder.layer.6.output.dense.bias', 'bert.encoder.layer.6.output.LayerNorm.weight', 'bert.encoder.layer.6.output.LayerNorm.bias', 'bert.encoder.layer.7.attention.self.query.weight', 'bert.encoder.layer.7.attention.self.query.bias', 'bert.encoder.layer.7.attention.self.key.weight', 'bert.encoder.layer.7.attention.self.key.bias', 'bert.encoder.layer.7.attention.self.value.weight', 'bert.encoder.layer.7.attention.self.value.bias', 'bert.encoder.layer.7.attention.output.dense.weight', 'bert.encoder.layer.7.attention.output.dense.bias', 'bert.encoder.layer.7.attention.output.LayerNorm.weight', 'bert.encoder.layer.7.attention.output.LayerNorm.bias', 'bert.encoder.layer.7.intermediate.dense.weight', 'bert.encoder.layer.7.intermediate.dense.bias', 'bert.encoder.layer.7.output.dense.weight', 'bert.encoder.layer.7.output.dense.bias', 'bert.encoder.layer.7.output.LayerNorm.weight', 'bert.encoder.layer.7.output.LayerNorm.bias', 'bert.encoder.layer.8.attention.self.query.weight', 'bert.encoder.layer.8.attention.self.query.bias', 'bert.encoder.layer.8.attention.self.key.weight', 'bert.encoder.layer.8.attention.self.key.bias', 'bert.encoder.layer.8.attention.self.value.weight', 'bert.encoder.layer.8.attention.self.value.bias', 'bert.encoder.layer.8.attention.output.dense.weight', 'bert.encoder.layer.8.attention.output.dense.bias', 'bert.encoder.layer.8.attention.output.LayerNorm.weight', 'bert.encoder.layer.8.attention.output.LayerNorm.bias', 'bert.encoder.layer.8.intermediate.dense.weight', 'bert.encoder.layer.8.intermediate.dense.bias', 'bert.encoder.layer.8.output.dense.weight', 'bert.encoder.layer.8.output.dense.bias', 'bert.encoder.layer.8.output.LayerNorm.weight', 'bert.encoder.layer.8.output.LayerNorm.bias', 'bert.encoder.layer.9.attention.self.query.weight', 'bert.encoder.layer.9.attention.self.query.bias', 'bert.encoder.layer.9.attention.self.key.weight', 'bert.encoder.layer.9.attention.self.key.bias', 'bert.encoder.layer.9.attention.self.value.weight', 'bert.encoder.layer.9.attention.self.value.bias', 'bert.encoder.layer.9.attention.output.dense.weight', 'bert.encoder.layer.9.attention.output.dense.bias', 'bert.encoder.layer.9.attention.output.LayerNorm.weight', 'bert.encoder.layer.9.attention.output.LayerNorm.bias', 'bert.encoder.layer.9.intermediate.dense.weight', 'bert.encoder.layer.9.intermediate.dense.bias', 'bert.encoder.layer.9.output.dense.weight', 'bert.encoder.layer.9.output.dense.bias', 'bert.encoder.layer.9.output.LayerNorm.weight', 'bert.encoder.layer.9.output.LayerNorm.bias', 'bert.encoder.layer.10.attention.self.query.weight', 'bert.encoder.layer.10.attention.self.query.bias', 'bert.encoder.layer.10.attention.self.key.weight', 'bert.encoder.layer.10.attention.self.key.bias', 'bert.encoder.layer.10.attention.self.value.weight', 'bert.encoder.layer.10.attention.self.value.bias', 'bert.encoder.layer.10.attention.output.dense.weight', 'bert.encoder.layer.10.attention.output.dense.bias', 'bert.encoder.layer.10.attention.output.LayerNorm.weight', 'bert.encoder.layer.10.attention.output.LayerNorm.bias', 'bert.encoder.layer.10.intermediate.dense.weight', 'bert.encoder.layer.10.intermediate.dense.bias', 'bert.encoder.layer.10.output.dense.weight', 'bert.encoder.layer.10.output.dense.bias', 'bert.encoder.layer.10.output.LayerNorm.weight', 'bert.encoder.layer.10.output.LayerNorm.bias', 'bert.encoder.layer.11.attention.self.query.weight', 'bert.encoder.layer.11.attention.self.query.bias', 'bert.encoder.layer.11.attention.self.key.weight', 'bert.encoder.layer.11.attention.self.key.bias', 'bert.encoder.layer.11.attention.self.value.weight', 'bert.encoder.layer.11.attention.self.value.bias', 'bert.encoder.layer.11.attention.output.dense.weight', 'bert.encoder.layer.11.attention.output.dense.bias', 'bert.encoder.layer.11.attention.output.LayerNorm.weight', 'bert.encoder.layer.11.attention.output.LayerNorm.bias', 'bert.encoder.layer.11.intermediate.dense.weight', 'bert.encoder.layer.11.intermediate.dense.bias', 'bert.encoder.layer.11.output.dense.weight', 'bert.encoder.layer.11.output.dense.bias', 'bert.encoder.layer.11.output.LayerNorm.weight', 'bert.encoder.layer.11.output.LayerNorm.bias', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing LayoutLMModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing LayoutLMModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LayoutLMModel were not initialized from the model checkpoint at data/models/layoutlm-base-uncased and are newly initialized: ['embeddings.word_embeddings.weight', 'embeddings.position_embeddings.weight', 'embeddings.x_position_embeddings.weight', 'embeddings.y_position_embeddings.weight', 'embeddings.h_position_embeddings.weight', 'embeddings.w_position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.LayerNorm.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.bias', 'pooler.dense.weight', 'pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "layout_lm_config = AutoConfig.from_pretrained(MODEL_NAME)\n",
    "model = AutoModel.from_pretrained(MODEL_NAME, config=layout_lm_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2083c310269142a383f99a7afe73a794",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=391.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer_layout = AutoTokenizer.from_pretrained(MODEL_NAME)        \n",
    "entries = dict()\n",
    "for id_d, content in tqdm(dataset.items()):\n",
    "    entries[id_d] = dict()\n",
    "    for id_c, ui_element in content[\"ui\"].items():\n",
    "        encoded_ui = convert_ui_to_feature(ui_element, largest, tokenizer_layout)\n",
    "        entries[id_d][id_c] = model(**encoded_ui)[1]\n",
    "    break\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(random_state=1, n_iter=15000, metric=\"cosine\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08c7a8fd9a0f4c88a12a95f07f051742",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             x           y  original_x  original_y                     text  \\\n",
      "0   166.422272 -328.975220   45.833334  148.437500                            \n",
      "1    21.001556  440.812988  435.416669  832.031250                0 . 06 mb   \n",
      "2  -315.506958   47.213257  815.972209  755.468726                 add page   \n",
      "3   466.669525   92.790031    4.861111  868.749976                            \n",
      "4   -62.631218 -125.630699  336.111098  868.749976                            \n",
      "5   189.698395  -23.608255  863.888860  868.749976                            \n",
      "6   251.338791  276.411499  174.999997   41.406251                 document   \n",
      "7  -100.206558 -423.738770    0.000000   32.812499              navigate up   \n",
      "8  -264.106934  325.509735  174.999997   74.609377          march 21 , 2017   \n",
      "9   -24.820675  143.883820  883.333325   38.281251                    close   \n",
      "10 -342.625977 -234.496140    0.000000  934.374988  navigationbarbackground   \n",
      "11  423.978302 -211.758224    0.000000    0.000000      statusbarbackground   \n",
      "\n",
      "                                   inst  \n",
      "0   select item at the top right corner  \n",
      "1   select item at the top right corner  \n",
      "2   select item at the top right corner  \n",
      "3   select item at the top right corner  \n",
      "4   select item at the top right corner  \n",
      "5   select item at the top right corner  \n",
      "6   select item at the top right corner  \n",
      "7   select item at the top right corner  \n",
      "8   select item at the top right corner  \n",
      "9   select item at the top right corner  \n",
      "10  select item at the top right corner  \n",
      "11  select item at the top right corner  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for id_d, content in tqdm(entries.items()):\n",
    "    input_emb = list()\n",
    "    instructions = list()\n",
    "    text_content = list()\n",
    "    original_x = list()\n",
    "    original_y = list()\n",
    "    for id_c, ui_element in content.items():\n",
    "        input_emb.append(ui_element.tolist()[0])\n",
    "        text_content.append(dataset[id_d][\"ui\"][id_c][\"text\"])\n",
    "        original_x.append(dataset[id_d][\"ui\"][id_c][\"x0\"])\n",
    "        original_y.append(dataset[id_d][\"ui\"][id_c][\"y0\"])\n",
    "        instructions.append(dataset[id_d][\"instruction\"])\n",
    "        \n",
    "    embs = tsne.fit_transform(input_emb)\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    df['x'] = embs[:, 0]\n",
    "    df['y'] = embs[:, 1]\n",
    "    df['original_x'] = original_x\n",
    "    df['original_y'] = original_y\n",
    "    df[\"text\"] = text_content\n",
    "    df[\"inst\"] = instructions\n",
    "    \n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "FS = (10, 8)\n",
    "fig, ax = plt.subplots(figsize=FS)\n",
    "# Make points translucent so we can visually identify regions with a high density of overlapping points\n",
    "ax.scatter(df.x, df.y);\n",
    "for i, txt in df[\"text\"].iteritems():\n",
    "    ax.annotate(txt, (df.x[i], df.y[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'select item at the top right corner',\n",
       " 'ui': {0: {'text': '',\n",
       "   'x0': 45.8333343,\n",
       "   'x1': 954.1666508,\n",
       "   'y0': 148.4375,\n",
       "   'y1': 829.6874762000001},\n",
       "  1: {'text': '0 . 06 mb',\n",
       "   'x0': 435.4166687,\n",
       "   'x1': 564.5833610999999,\n",
       "   'y0': 832.03125,\n",
       "   'y1': 857.8125237999999},\n",
       "  2: {'text': 'add page',\n",
       "   'x0': 815.972209,\n",
       "   'x1': 990.9722209,\n",
       "   'y0': 755.4687262000001,\n",
       "   'y1': 868.7499762000001},\n",
       "  3: {'text': '',\n",
       "   'x0': 4.8611113,\n",
       "   'x1': 140.9722269,\n",
       "   'y0': 868.7499762000001,\n",
       "   'y1': 934.3749881},\n",
       "  4: {'text': '',\n",
       "   'x0': 336.11109849999997,\n",
       "   'x1': 668.0555343999999,\n",
       "   'y0': 868.7499762000001,\n",
       "   'y1': 934.3749881},\n",
       "  5: {'text': '',\n",
       "   'x0': 863.8888597,\n",
       "   'x1': 1000.0,\n",
       "   'y0': 868.7499762000001,\n",
       "   'y1': 934.3749881},\n",
       "  6: {'text': 'document',\n",
       "   'x0': 174.99999699999998,\n",
       "   'x1': 422.9166806,\n",
       "   'y0': 41.406251499999996,\n",
       "   'y1': 74.60937650000001},\n",
       "  7: {'text': 'navigate up',\n",
       "   'x0': 0.0,\n",
       "   'x1': 136.1111104,\n",
       "   'y0': 32.812498500000004,\n",
       "   'y1': 109.375},\n",
       "  8: {'text': 'march 21 , 2017',\n",
       "   'x0': 174.99999699999998,\n",
       "   'x1': 452.0833194,\n",
       "   'y0': 74.60937650000001,\n",
       "   'y1': 100.39062799999999},\n",
       "  9: {'text': 'close',\n",
       "   'x0': 883.3333254,\n",
       "   'x1': 1000.0,\n",
       "   'y0': 38.2812507,\n",
       "   'y1': 103.90625150000001},\n",
       "  10: {'text': 'navigationbarbackground',\n",
       "   'x0': 0.0,\n",
       "   'x1': 1000.0,\n",
       "   'y0': 934.3749881,\n",
       "   'y1': 1000.0},\n",
       "  11: {'text': 'statusbarbackground',\n",
       "   'x0': 0.0,\n",
       "   'x1': 1000.0,\n",
       "   'y0': 0.0,\n",
       "   'y1': 32.812498500000004}},\n",
       " 'label': 9}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:oneshot_ipa] *",
   "language": "python",
   "name": "conda-env-oneshot_ipa-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
